# Fase 3: Optimizaci√≥n CIS (Counterfactual Internal States)

## üìã Tabla de Contenidos
- [Qu√© es CIS Optimization](#qu√©-es-cis-optimization)
- [Diferencia con Causal Check](#diferencia-con-causal-check)
- [Objetivo de Esta Fase](#objetivo-de-esta-fase)
- [C√≥mo Funciona](#c√≥mo-funciona)
- [Implementaci√≥n](#implementaci√≥n)
- [M√©tricas y Evaluaci√≥n](#m√©tricas-y-evaluaci√≥n)
- [Archivos a Crear](#archivos-a-crear)
- [Flujo de Ejecuci√≥n](#flujo-de-ejecuci√≥n)

---

## üéØ Qu√© es CIS Optimization

**CIS (Counterfactual Internal State)** es una perturbaci√≥n m√≠nima de activaciones internas que logra cambiar la predicci√≥n del modelo de un hecho verdadero a uno contrafactual.

### Ejemplo Concreto

**Hecho Real:**
- Prompt: `"The Eiffel Tower is located in"`
- Predicci√≥n: `" Paris"` (correcto)

**Objetivo CIS:**
- Encontrar el vector Œ¥ m√°s peque√±o posible que:
  - Agregado a la capa 16, posici√≥n -1
  - Cambie la predicci√≥n a `" Rome"` (contrafactual)
  - Tenga la norma L2 m√≠nima

**Resultado:**
- Œ¥ optimizado con norma ||Œ¥|| = 0.15 (por ejemplo)
- Esto mide qu√© tan "r√≠gida" es la representaci√≥n factual
- Norma peque√±a = f√°cil de cambiar (d√©bil rigidez factual)
- Norma grande = dif√≠cil de cambiar (fuerte rigidez factual)

---

## üîÑ Diferencia con Causal Check

| Aspecto | Causal Check (Fase 2) | CIS Optimization (Fase 3) |
|---------|----------------------|--------------------------|
| **Delta** | Aleatorio (Gaussian) | **Optimizado con gradientes** |
| **Objetivo** | Verificar que hooks funcionan | **Encontrar perturbaci√≥n m√≠nima** |
| **Target** | Ninguno (solo observar cambios) | **Target espec√≠fico** (ej: " Rome") |
| **Optimizaci√≥n** | No hay | **S√≠ - gradient descent** |
| **Medici√≥n** | Cambio cualitativo | **Costo geom√©trico cuantitativo** |
| **Uso** | Sanity check | **Experimento cient√≠fico real** |

### En Resumen

- **Fase 2 (Causal Check)**: "¬øFuncionan los hooks?"
  - Delta = random
  - Solo verificamos que algo cambia

- **Fase 3 (CIS Optimization)**: "¬øCu√°l es el costo de cambiar este hecho?"
  - Delta = optimizado
  - Medimos rigidez factual

---

## üéØ Objetivo de Esta Fase

### Pregunta Cient√≠fica

**"¬øQu√© tan r√≠gidas son las representaciones factuales en LLMs?"**

Espec√≠ficamente:
1. ¬øCu√°l es la **perturbaci√≥n m√≠nima** necesaria para cambiar un hecho?
2. ¬øVar√≠a este costo entre diferentes hechos?
3. ¬øQu√© capas son m√°s cr√≠ticas para el conocimiento factual?

### Resultados Esperados

1. **Geometric Cost**: Norma L2 de la perturbaci√≥n m√≠nima
   - Bajo (< 0.1): Hecho d√©bilmente codificado
   - Medio (0.1-1.0): Codificaci√≥n normal
   - Alto (> 1.0): Hecho fuertemente arraigado

2. **Success Rate**: % de veces que logramos el flip
   - 100%: Siempre podemos cambiar la predicci√≥n
   - 50-99%: A veces funciona
   - < 50%: Hecho muy r√≠gido o target inalcanzable

3. **Layer Sensitivity**: Qu√© capas son m√°s efectivas
   - Hip√≥tesis: Capas medias (12-20) m√°s efectivas

---

## ‚öôÔ∏è C√≥mo Funciona

### Pipeline Completo

```
1. Cargar modelo (Mistral-7B)
   ‚Üì
2. Seleccionar hecho factual
   Ejemplo: "Eiffel Tower" ‚Üí " Paris"
   ‚Üì
3. Definir target contrafactual
   Ejemplo: " Rome"
   ‚Üì
4. Inicializar delta (peque√±o random o zeros)
   Œ¥‚ÇÄ ‚àà ‚Ñù^4096
   ‚Üì
5. LOOP de optimizaci√≥n (N pasos):
   ‚îÇ
   ‚îú‚îÄ 5a. Forward pass CON hook
   ‚îÇ      logits = model(prompt, con Œ¥ en capa L)
   ‚îÇ
   ‚îú‚îÄ 5b. Calcular loss
   ‚îÇ      L = -log P(target) + Œª¬∑||Œ¥||¬≤
   ‚îÇ
   ‚îÇ      Donde:
   ‚îÇ      - P(target) = probabilidad del token target
   ‚îÇ      - Œª = peso de regularizaci√≥n (ej: 0.01)
   ‚îÇ      - Queremos MAXIMIZAR P(target)
   ‚îÇ      - Queremos MINIMIZAR ||Œ¥||
   ‚îÇ
   ‚îú‚îÄ 5c. Backward pass
   ‚îÇ      ‚àáŒ¥ = ‚àÇL/‚àÇŒ¥
   ‚îÇ
   ‚îú‚îÄ 5d. Gradient descent
   ‚îÇ      Œ¥ ‚Üê Œ¥ - Œ±¬∑‚àáŒ¥
   ‚îÇ      (Œ± = learning rate, ej: 0.05)
   ‚îÇ
   ‚îî‚îÄ 5e. Check convergencia
        Si P(target) > umbral (ej: 0.5): STOP
   ‚Üì
6. Evaluar resultado final
   - Costo geom√©trico: ||Œ¥_final||
   - Success: ¬øEs target el top-1?
   - Collateral: ¬øCambiaron otros tokens?
```

### Funci√≥n de Loss

```python
def cis_loss(logits, target_token_id, delta, reg_weight=0.01):
    """
    Loss para CIS optimization.

    Args:
        logits: [vocab_size] logits del modelo
        target_token_id: ID del token que queremos
        delta: [hidden_size] perturbaci√≥n actual
        reg_weight: peso de regularizaci√≥n L2

    Returns:
        loss: escalar para minimizar
    """
    # Probabilidad del target (queremos maximizarla)
    probs = torch.softmax(logits, dim=-1)
    target_prob = probs[target_token_id]

    # Loss principal: negative log likelihood
    # (minimizar = maximizar probabilidad)
    nll_loss = -torch.log(target_prob + 1e-10)

    # Regularizaci√≥n: penalizar norma grande de delta
    # (queremos delta peque√±o)
    reg_loss = reg_weight * (delta ** 2).sum()

    # Loss total
    total_loss = nll_loss + reg_loss

    return total_loss
```

### ¬øPor Qu√© Funciona?

1. **Backprop a trav√©s del modelo**: PyTorch calcula ‚àáŒ¥ autom√°ticamente
2. **Hook modifica activaciones**: Œ¥ se suma en forward pass
3. **Gradiente nos dice**: "En qu√© direcci√≥n cambiar Œ¥ para aumentar P(target)"
4. **Regularizaci√≥n L2**: Evita que Œ¥ crezca descontroladamente

---

## üíª Implementaci√≥n

### Archivos a Crear

#### 1. `src/cis/cis_optimizer.py`

**Clase principal: `CISOptimizer`**

```python
class CISOptimizer:
    """Optimiza perturbaciones para lograr cambios contrafactuales."""

    def __init__(
        self,
        model,
        tokenizer,
        layer_idx: int,
        token_position: int = -1,
        device: str = "cuda"
    ):
        """
        Args:
            model: Transformer model (frozen)
            tokenizer: Tokenizer
            layer_idx: Qu√© capa intervenir
            token_position: Qu√© token perturbar (-1 = last)
            device: cuda/cpu
        """
        self.model = model
        self.tokenizer = tokenizer
        self.layer_idx = layer_idx
        self.token_position = token_position
        self.device = device
        self.hidden_size = get_hidden_size(model)

    def optimize(
        self,
        prompt: str,
        target_completion: str,
        max_steps: int = 200,
        learning_rate: float = 0.05,
        reg_weight: float = 0.01,
        tolerance: float = 1e-4,
        early_stop_margin: float = 0.5,
    ) -> Dict[str, Any]:
        """
        Encuentra la perturbaci√≥n m√≠nima para lograr target.

        Returns:
            {
                'delta': torch.Tensor,          # Perturbaci√≥n optimizada
                'final_loss': float,            # Loss final
                'geometric_cost': float,        # ||delta||
                'success': bool,                # ¬øLogr√≥ el flip?
                'target_prob': float,           # P(target) final
                'num_steps': int,               # Pasos usados
                'top_predictions': List[Dict],  # Top-5 final
            }
        """
        # Implementaci√≥n aqu√≠...
```

**M√©todos clave:**

```python
def _forward_with_intervention(self, input_ids, delta):
    """Forward pass con delta inyectado."""
    # 1. Attach hook con delta
    # 2. Run model
    # 3. Remove hook
    # 4. Return logits

def _compute_loss(self, logits, target_id, delta, reg_weight):
    """Calcula loss CIS."""
    # NLL + L2 regularization

def _backward_step(self, loss, delta, learning_rate):
    """Gradient descent step."""
    # 1. loss.backward()
    # 2. delta -= lr * delta.grad
    # 3. delta.grad.zero_()
```

#### 2. `src/experiments/run_cis_optimization.py`

**Script para experimentos CIS:**

```python
def run_cis_experiment(config_path: str):
    """
    Ejecuta optimizaci√≥n CIS en un hecho.

    1. Carga modelo
    2. Carga hecho de config o dataset
    3. Define target contrafactual
    4. Optimiza delta
    5. Reporta resultados
    """
    # Load model
    model, tokenizer = load_model_and_tokenizer(...)

    # Setup optimizer
    optimizer = CISOptimizer(
        model=model,
        tokenizer=tokenizer,
        layer_idx=config['layer'],
        token_position=config['token_position']
    )

    # Optimize
    result = optimizer.optimize(
        prompt="The Eiffel Tower is located in",
        target_completion=" Rome",
        max_steps=200,
        learning_rate=0.05,
    )

    # Report
    print(f"Success: {result['success']}")
    print(f"Geometric Cost: {result['geometric_cost']:.4f}")
    print(f"Target Probability: {result['target_prob']:.4f}")
```

#### 3. `src/metrics/factual_rigidity.py`

**M√©tricas para evaluar resultados:**

```python
def compute_geometric_cost(delta: torch.Tensor) -> float:
    """L2 norm of perturbation."""
    return delta.norm(p=2).item()

def compute_success_rate(results: List[Dict]) -> float:
    """Percentage of successful flips."""
    successes = sum(r['success'] for r in results)
    return successes / len(results)

def compute_collateral_effects(
    baseline_preds: List[str],
    intervention_preds: List[str]
) -> Dict[str, Any]:
    """Measure unintended changes."""
    # ¬øCu√°ntos tokens en top-5 cambiaron?
    # ¬øQu√© tan diferente es la distribuci√≥n?
```

#### 4. Actualizar `config/experiment.yaml`

```yaml
seed: 0
model_config: config/model.yaml
data_path: data/counterfact_subset.json

# Fact to test
subject: "Eiffel Tower"
relation: "located in"
expected_completion: " Paris"

# CIS Optimization
cis_optimization:
  target_completion: " Rome"     # Counterfactual target
  layer: 16                      # Which layer to intervene
  token_position: -1             # Which token (-1 = last)
  max_steps: 200                 # Max optimization steps
  learning_rate: 0.05            # Step size
  reg_weight: 0.01               # L2 regularization weight
  tolerance: 1.0e-4              # Convergence threshold
  early_stop_margin: 0.5         # Stop if P(target) > this

# Analysis
analysis:
  k_alternatives: 5              # Top-k to report
  measure_collateral: true       # Track side effects
```

---

## üìä M√©tricas y Evaluaci√≥n

### M√©tricas Principales

#### 1. **Geometric Cost** (Principal)
```python
cost = ||Œ¥_optimized||_2
```
- **Interpretaci√≥n**: Qu√© tan dif√≠cil es cambiar este hecho
- **Rango t√≠pico**: 0.01 - 10.0
- **Bajo (< 0.5)**: F√°cil de cambiar, d√©bil rigidez
- **Alto (> 2.0)**: Dif√≠cil de cambiar, fuerte rigidez

#### 2. **Success Rate**
```python
success = (top_1_prediction == target_token)
```
- **Interpretaci√≥n**: ¬øLogramos el flip?
- **100%**: Siempre exitoso
- **0%**: Nunca exitoso (target imposible o layer incorrecta)

#### 3. **Target Probability**
```python
target_prob = P(target | prompt, Œ¥)
```
- **Interpretaci√≥n**: Confianza del modelo en el target
- **> 0.5**: Target es top-1
- **< 0.1**: Target casi imposible

#### 4. **Optimization Convergence**
```python
num_steps_to_converge = steps_until(P(target) > threshold)
```
- **Interpretaci√≥n**: Qu√© tan r√°pido converge
- **Pocos pasos (< 50)**: F√°cil de optimizar
- **Muchos pasos (> 150)**: Dif√≠cil de optimizar

### M√©tricas Secundarias

#### 5. **Collateral Effects**
```python
collateral = |{tokens changed in top-5}| / 5
```
- **Interpretaci√≥n**: Efectos secundarios de la intervenci√≥n
- **0.0**: Solo cambi√≥ el target
- **1.0**: Toda la distribuci√≥n cambi√≥

#### 6. **Relative Rank Change**
```python
rank_change = rank_baseline(target) - rank_intervention(target)
```
- **Interpretaci√≥n**: Cu√°nto subi√≥ el target en ranking
- **Ejemplo**: rank 50 ‚Üí rank 1 = cambio de 49

---

## üìÅ Archivos a Crear

### Estructura Completa

```
cis_factual_llm/
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ cis/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cis_optimizer.py          # ‚Üê NUEVO: Clase CISOptimizer
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ experiments/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ run_single_fact.py        # ‚úì Ya existe
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ run_causal_check.py       # ‚úì Ya existe
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run_cis_optimization.py   # ‚Üê NUEVO: Experimento CIS
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ metrics/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ factual_rigidity.py       # ‚Üê ACTUALIZAR: M√©tricas CIS
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ hooks/
‚îÇ       ‚îî‚îÄ‚îÄ residual_hooks.py         # ‚úì Ya existe
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ model.yaml                    # ‚úì Ya existe
‚îÇ   ‚îî‚îÄ‚îÄ experiment.yaml               # ‚Üê ACTUALIZAR: Config CIS
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ CAUSAL_CHECK_GUIDE.md         # ‚úì Ya existe
‚îÇ   ‚îî‚îÄ‚îÄ CIS_OPTIMIZATION_GUIDE.md     # ‚Üê NUEVO: Gu√≠a CIS
‚îÇ
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ test_residual_hooks.py        # ‚úì Ya existe
    ‚îî‚îÄ‚îÄ test_cis_optimizer.py         # ‚Üê NUEVO: Tests CIS
```

---

## üîÑ Flujo de Ejecuci√≥n

### Paso a Paso

#### 1. **Preparaci√≥n**
```bash
# Verificar que causal check funciona
python src/experiments/run_causal_check.py --config config/experiment.yaml

# Output esperado:
# ‚úì Causal effect detected
# ‚úì Hook mechanism verified
```

#### 2. **Configurar Experimento CIS**
```yaml
# config/experiment.yaml
cis_optimization:
  target_completion: " Rome"    # Tu target contrafactual
  layer: 16                     # Capa media
  max_steps: 200
  learning_rate: 0.05
```

#### 3. **Ejecutar Optimizaci√≥n**
```bash
python src/experiments/run_cis_optimization.py --config config/experiment.yaml
```

#### 4. **Output Esperado**
```
================================================================================
CIS OPTIMIZATION: Counterfactual Internal State
================================================================================

Fact: "The Eiffel Tower is located in"
Baseline prediction: " Paris" (prob=0.823)
Target: " Rome"

Optimizing delta at layer 16, token position -1...

Step   0: Loss=5.234, P(target)=0.001, ||Œ¥||=0.000
Step  10: Loss=3.456, P(target)=0.023, ||Œ¥||=0.045
Step  20: Loss=2.123, P(target)=0.089, ||Œ¥||=0.098
Step  30: Loss=1.234, P(target)=0.234, ||Œ¥||=0.142
Step  40: Loss=0.789, P(target)=0.456, ||Œ¥||=0.178
Step  50: Loss=0.456, P(target)=0.623, ||Œ¥||=0.189  ‚Üê Target is top-1!

‚úì Optimization converged in 50 steps

================================================================================
RESULTS
================================================================================

Success: ‚úì YES
Geometric Cost: 0.189
Target Probability: 0.623
Convergence: 50 steps

Top-5 predictions (with intervention):
  1. " Rome"      prob=0.623  ‚Üê TARGET ‚úì
  2. " Paris"     prob=0.201
  3. " France"    prob=0.089
  4. " Italy"     prob=0.045
  5. " Europe"    prob=0.023

Collateral Effects: 4/5 tokens changed
Relative Rank Change: 49 (rank 50 ‚Üí rank 1)

================================================================================
INTERPRETATION
================================================================================

‚úì Successfully flipped "Paris" ‚Üí "Rome"
‚úì Geometric cost = 0.189 (moderate rigidity)
‚úì Converged quickly (50 steps)

This fact has MODERATE factual rigidity:
- Not too easy to change (cost > 0.1)
- Not too hard to change (cost < 1.0)
- Middle layers effective for intervention
```

---

## üéì Conceptos Clave

### ¬øQu√© es "Geometric Cost"?

**Intuici√≥n geom√©trica:**

Imagina el espacio de activaciones como un paisaje de N dimensiones (N=4096 para Mistral).

- **Punto A**: Activaciones que predicen " Paris" (baseline)
- **Punto B**: Activaciones que predicen " Rome" (target)
- **Distancia A‚ÜíB**: Geometric cost

```
Espacio de activaciones (4096D):

        " Paris"              " Rome"
           üóº                    üèõÔ∏è
           ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ Œ¥ ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫      ‚îÇ
           A                    B

||Œ¥|| = distancia m√°s corta de A a B
```

### ¬øQu√© aprenderemos?

1. **Rigidez Factual Global**
   - Promedio de costs sobre muchos hechos
   - "¬øQu√© tan estables son los hechos en general?"

2. **Varianza entre Hechos**
   - Algunos hechos: cost bajo (f√°cil cambiar)
   - Otros hechos: cost alto (dif√≠cil cambiar)
   - "¬øHay hechos m√°s 'arraigados' que otros?"

3. **Sensibilidad de Capas**
   - Comparar costs en diferentes layers
   - "¬øQu√© capas codifican conocimiento factual?"

4. **Targets Alcanzables**
   - Algunos targets: f√°cil alcanzar
   - Otros targets: imposible alcanzar
   - "¬øQu√© limita los cambios contrafactuales?"

---

## üöÄ Siguientes Pasos

### Implementaci√≥n Incremental

#### Fase 3.1: CIS Optimizer B√°sico
```python
# Solo lo esencial
- Clase CISOptimizer
- M√©todo optimize() b√°sico
- Loss = NLL + L2 regularization
- Sin early stopping avanzado
```

#### Fase 3.2: Experimento Single-Fact
```python
# Probar en un hecho
- run_cis_optimization.py
- Config YAML
- Output detallado
```

#### Fase 3.3: M√©tricas y An√°lisis
```python
# Evaluar resultados
- Geometric cost
- Success rate
- Collateral effects
```

#### Fase 3.4: Batch Processing
```python
# Escalar a m√∫ltiples hechos
- Loop sobre dataset
- Guardar resultados en JSON
- Estad√≠sticas agregadas
```

---

## üìö Referencias

### Papers Relevantes

1. **Causal Tracing** (Meng et al., 2022)
   - Locating factual knowledge in LLMs
   - Layer-wise attribution

2. **ROME** (Meng et al., 2022)
   - Rank-One Model Editing
   - Similar idea: minimal edits to change facts

3. **Activation Engineering** (Turner et al., 2023)
   - Steering model behavior with activations
   - Diferentes objetivos pero t√©cnica similar

### Recursos T√©cnicos

- **PyTorch Autograd**: https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html
- **Hook API**: https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_forward_hook
- **Optimizer Implementation**: https://pytorch.org/docs/stable/optim.html

---

## ‚ö†Ô∏è Consideraciones Importantes

### Hiperpar√°metros Cr√≠ticos

1. **Learning Rate** (`0.05` default)
   - Muy bajo (< 0.01): Convergencia lenta
   - Muy alto (> 0.5): Inestabilidad, overshoot
   - **Recomendaci√≥n**: Empezar con 0.05, ajustar si no converge

2. **Regularization Weight** (`0.01` default)
   - Muy bajo (< 0.001): Delta crece mucho, cost alto
   - Muy alto (> 0.1): No alcanza el target
   - **Recomendaci√≥n**: 0.01 para balance costo/√©xito

3. **Max Steps** (`200` default)
   - Muy pocos (< 50): Puede no converger
   - Muy muchos (> 500): Tiempo desperdiciado
   - **Recomendaci√≥n**: 200 suficiente para mayor√≠a de casos

### Limitaciones

1. **Targets imposibles**: Algunos targets nunca ser√°n top-1
   - Ejemplo: " XYZ123" (token inexistente/raro)
   - Soluci√≥n: Verificar que target est√° en vocabulario

2. **Local minima**: Optimizaci√≥n puede atorarse
   - Soluci√≥n: Reiniciar con diferente inicializaci√≥n

3. **Memoria GPU**: Mantener gradientes consume memoria
   - Soluci√≥n: Usar 4-bit quantization si necesario

---

## ‚úÖ Checklist de Implementaci√≥n

- [ ] Implementar `CISOptimizer` class
  - [ ] `__init__()` method
  - [ ] `optimize()` method
  - [ ] `_forward_with_intervention()`
  - [ ] `_compute_loss()`
  - [ ] `_backward_step()`

- [ ] Crear experimento `run_cis_optimization.py`
  - [ ] CLI arguments
  - [ ] Config loading
  - [ ] Optimizer setup
  - [ ] Results reporting

- [ ] Actualizar m√©tricas `factual_rigidity.py`
  - [ ] `compute_geometric_cost()`
  - [ ] `compute_collateral_effects()`
  - [ ] `analyze_convergence()`

- [ ] Actualizar config `experiment.yaml`
  - [ ] CIS optimization parameters
  - [ ] Target specification

- [ ] Crear gu√≠a `CIS_OPTIMIZATION_GUIDE.md`
  - [ ] Explicaci√≥n detallada
  - [ ] Ejemplos de uso
  - [ ] Interpretaci√≥n de resultados

- [ ] Tests `test_cis_optimizer.py`
  - [ ] Test b√°sico de optimizaci√≥n
  - [ ] Test de convergencia
  - [ ] Test de m√©tricas

- [ ] Documentar en README
  - [ ] Nueva secci√≥n de CIS
  - [ ] Ejemplos de uso
  - [ ] Resultados esperados

---

## üéØ Meta de Esta Fase

**Lograr esto:**

```bash
$ python src/experiments/run_cis_optimization.py --config config/experiment.yaml

# Output:
‚úì Successfully flipped "Paris" ‚Üí "Rome"
‚úì Geometric cost: 0.189
‚úì 50 optimization steps
‚úì Target probability: 0.623

Next: Run on full dataset to measure average factual rigidity
```

**Con esto demostraremos:**

1. ‚úÖ Podemos **medir cuantitativamente** la rigidez factual
2. ‚úÖ La optimizaci√≥n **converge** a perturbaciones m√≠nimas
3. ‚úÖ Los resultados son **interpretables** y **reproducibles**
4. ‚úÖ El sistema est√° **listo** para experimentos a escala

---

¬øListo para implementar? üöÄ
